# 2/2
## stork
- **[]** Autonomous Selective Parts-Based Tracking(未下载)
	- TIP

# 9/2
## stork
- **[]** Hierarchical Spatiotemporal Context-Aware Correlation Filters for Visual Tracking(未下载)
	- IEEE Transactions on Cybernetics

# 12/2
## detection
### Background——减少背景信息
- **[]** Accelerating Object Detection by Erasing Background Activations
	- arxiv
	- 先把背景消除在进行目标检测，并且加速了
	- *我们在目标检测（OD）网络的前面合并了一个轻量级的目标maks生成（OMG）网络，以便在将输入图像的背景区域送入OD网络之前将其清零。*
- **[]** Selective Convolutional Network: An Efficient Object Detector with Ignoring Background
	- ICASSP 2020，CCF_B，华中科大
	- `选择性卷积`，把不需要的背景信息排除，进而加速、高效的进行检测；
	- *基本思想是排除无关紧要的背景区域，从而有效地降低了计算成本，尤其是在特征提取期间。*


# 16/2
## stork
- **[]** Real-time object tracking via self-adaptive appearance modeling
	- Neurocomputing、SCI_2

# 20/2
- [x] :sunny: **[UpdateNet]** Learning the Model Update for Siamese Trackers 
	- ICCV 2019
	- 提出了一个简易的更新网络`UpdateNet`，并且可嵌入在`SiamFC`和`DaSiamRPN`里（文中说可以集成到其他的Siamese网络，可以尝试！），在速度影响很小的情况下提升了性能；
	- 结论中说道：*我们发现此线性更新的几个缺点，并建议将更新步骤作为优化问题来学习。* 确实更新机制没有调参，让网络自己学习的；
	- 值得注意的是训练策略，`多阶段学习`才有了这个`UpdateNet`；
	- 对实验的分析很到位，文章叙述的很好。
	> `note`:Change rate between contiguous frames.[Figure 4]
	> *分析计算了连续帧的模板之间的变化率δ，UpdateNet提供的自适应更新策略接近真实模板的变化率，UpdateNet的变化率遵循与真实情况相同的趋势。*
	> 但是变化率的大小与真实的还有点差别！**如何缩小这种变化率之间的差距？！**
	> 

# 21/2
## AAAI 2020
### SOT
- [x] **[SPSTracker]** SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking
	- `ATOM`改进
- **[MetaRTT]** Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning
	- 提出一种新的`元学习`跟踪框架
- [x] **[SiamFC++]** SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines
	- 基于`SiamFC`改进，并提出了一系列指导建议
- [x] **[GlobalTrack]** GlobalTrack: A Simple and Strong Baseline for Long-term Tracking
	- 借鉴检测做跟踪
- [x] **[DROL]** Discriminative and Robust Online Learning for Siamese Visual Tracking
	- 在Siamese框架下增加了一个判别分类模块

没找到
- **[]** Optical Flow in Deep Visual Tracking
- **[]** Release the power of online-training for robust visual tracking
### MOT
- **[]** DASOT: A Unified Framework Integrating Data Association and Single Object Tracking for Online Multi-Object Tracking
- **[]** Complementary-View Multiple Human Tracking


### other
- **[]** Pose-Assisted Multi-Camera Collaboration for Active Object Tracking
	- `Active Object Tracking` 主动目标跟踪

# 23/2
## tracking
- **[TADT]** Target-Aware Deep Tracking
	- CVPR 2019、已开源
	- 从新思考预训练的分类网络来做跟踪的backbone有哪些问题，并针对性的改进；
		- `问题`：*1、视觉跟踪中的目标可以是任意形式的，也就是说，从普通图像中预先训练的CNN模型对感兴趣的目标对象是不可知的，并且在将它们与背景分离时效果较差；2、经过预训练的神经网络注重增加类间差异，提取的深层特征对类内差异不敏感。因此，对于跟踪器来说，这些特征对于准确估计尺度变化、区分目标和具有相同类别标签的干扰器来说是不太有效的。3、当应用于跟踪任务时，只有很少的卷积过滤器可用于描述目标。高计算负荷。*
		- `改进`：*我们建议通过从预先训练的CNN层中选择最有效的滤波器来学习具有`回归损失`和`排序损失`的目标感知深度特征。* `具体来说`：通过使用全局平均池，卷积滤波器生成的梯度可以确定用于表示目标对象的滤波器的重要性。 为了选择最有效的卷积滤波器，我们设计了两种类型的目标损耗，以便在第一帧中的预训练深度模型之上执行反向传播。 我们使用铰链损失将预先训练的深度特征回归到由高斯函数生成的软标签，并使用梯度选择目标主动卷积滤波器。 我们使用具有成对距离的等级损失来搜索可识别尺度的卷积滤波器。 所选的最重要的过滤器的激活是这项工作中的目标感知功能。
	- 两个损失的公式说明出还不是太理解？
	- 这个还是在预训练的分类网络（VGG）上进行针对跟踪任务进行选择特征表示的比较好的卷积核，可以看成另类的`通道注意力`；
		
		> 并没有只针对跟踪任务进行backbone设计或是改进。
	- 性能还不错，速度>30fps
	###  backbone
	- **[SKNet]** Selective Kernel Networks
		- CVPR 2019
	- 自适应选择卷积核，获取跟好的感受野；
	
	> `TADT` + `SKNet` ???!!!
	> 

### `TADT` 被引
- **[]** Object Tracking Based on Channel Attention
	- IEEE Access
	- *在这项工作中，我们提出了一种基于频道关注度的改进的最新跟踪器MDNet，从而提出了一种对象跟踪方法，该方法可以通过抑制背景和突出显示对象来区分相似的对象。 我们**将`频道关注模块`和`组标准化`集成到MDNet网络中**。 为了验证提议的跟踪器的有效性，我们将其与OTB-100，OTB-50和CVPR 2013数据集的成功率和精确度进行了比较，并与许多现有的最新跟踪器进行了比较。 测试结果证明了该算法的有效性和改进。*

- **[]** Visual Object Tracking with Adaptive Structural Convolutional Network
	- Knowledge-Based Systems（SCI_1）

# 24/2
- **[]** Learning Objectness Transfer Networks for Visual Tracking
	- IEEE Access 
	- *现有的深度跟踪器主要使用在对象识别训练集上预先训练的深度神经网络来生成深度特征作为目标表示。 但是，预训练的深度特征不能有效地表示任意形式的目标对象，而目标物体可能对于预训练的深度网络是看不见的。 为了缩小表示能力的差距，我们建议在预先训练的深度网络内传递客观性信息。 所传输的对象信息用于生成深层特征，这些深层特征可识别目标对象的任何任意形式，以实现强大的视觉跟踪。 具体来说，我们在**预先训练的深度模型之上设计了一个新颖的网络分支，以执行增量转移学习。 具有传输的对象信息的学习网络有助于精确定位外观变化较大的目标对象**。 在标准基准数据集上的实验结果表明，所提出的算法相对于最新的跟踪器具有良好的性能*