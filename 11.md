# 11/2



# 11/5
## `Martin Danelljan`
- **[DiMP]** Learning Discriminative Model Prediction for Tracking
	- `discriminative learning`
	- 分析了Siamese learning framework 的[缺陷](https://blog.csdn.net/sinat_31184961/article/details/89512108)：
		- Siamese的网络框架一般都只是把模板割出来，忽略了背景信息的利用，而背景的信息对目标的检测定位也是至关重要的；
		- 因为跟踪一般都是很多没有见过的类，通过offline学习的相似性度量可能不是很适用；
		- 没有一个合适的模型更新方式。
	- 针对性的提出两个[创新点](https://gkwang.net/dimp/)：
		- 首先，作者使用了模型预测网络，并且通过具有判别能力Loss进行优化；
		- 还设计了快速迭代方法进行优化。
			- 在每次梯度下降时，朝向梯度最陡的地方，以计算得到的最优步长进行下降；
			- 设计一个权重预测模块，为模型提供较好的初始化。
	- 还有很多值得学习的地方，比如训练的时候采用的一系列图片，不是以往的单张图片；公式推导，数学很强，很多不是太懂！

- **[ATOM]** ATOM: Accurate tracking by overlap maximization


# 11/11
## `SE-Net`
- **[SE-Net]** 
- **[CMPE-SE]** Competitive Inner-Imaging Squeeze and Excitation for Residual Network

## `Cbam`
- **[Cbam]** 
- **[GENet]** Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
- **[BAM]** BAM: Bottleneck Attention Module
- **[GCNet]** GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond
	- 感觉有戏，可以试试（上面三个没有track的paper）
	- `non-local network`

## `dense` 同一作者Gao Huang
- **[DenesNet]** 
- **[CondenseNet]** CondenseNet: An Efficient DenseNet using Learned Group Convolutions
- **[MSDNet]** Multi-Scale Dense Networks for Resource Effciient Imagine Classification

## `Motion Guided Attention`
- **[]** Motion Guided Attention for Video Salient Object Detection
	- ICCV2019
	- 运动引导，这点看看，没准可以用上

## `pruning`
- **[]** Rethinking the Value of Network Rruning

## `tracking` 
### `attention`
- **[RMA-Siam]** Relation-aware Multiple Attention Siamese Networks for Robust Visual Tracking  √
	- bmvc2019(CCF_C)
	- 利用`多个注意`图发现最显著的目标部分，并采用正交正则化方法`保证局部`模式的多样性。然后应用`关系感知语义补偿`来获取零件特征之间的依赖关系。
	- 在基准SiamRPN上做的改进，主要针对`遮挡`问题，效果很不错，速度也很快（180+fps）
	- 感觉多个小创新组合在一起，效果也不错，就是才是一个C类会议。
	- **[]** A2-Nets: Double Attention Networks
	- **[StructSiam]** Structured Siamese Network for Real-Time Visual Tracking
		- `RMA-Siam`和他很像，但有所改进，都是`部分、结构`上做创新
		- 也是卢老师的 ECCV2018

	- **[]** RePr: Improved Training of Convolutional Filters
	- 
### `detection`
- **[]** Bridging the Gap Between Detection and Tracking: A Unified Approach  √
	- ICCV2019
	- 从检测的角度来说思考的track，提供了一个框架，一个新思路，`我们认为跟踪是一个一次目标检测和少次实例分类的联合任务`，还有`meta learning`
	- 就是效果相比而言没有啥提升或是持平，速度上更是只有几帧（有更新策略），相比Siamese差得远（速度提升下一个创新点？！！）

### `Knowledge Distillation`
- **[]** Teacher-Students Knowledge Distillation for Siamese Trackers  √
	- Jianbing Shen 北京理工大学，同工作 SiamFC-tri (ECCV2018)、HASiam (SCI_1)，
	- 第一个对跟踪问题采用知识蒸馏来压缩模型的，压缩的效果确实很好（13x—18x），性能没啥影响甚至还有所提升，速度提升了两三倍

### `Gradient-Guided`
- **[GradNet]** GradNet: Gradient-Guided Network for Visual Object Tracking
	- ICCV2019 `oral` ，Huchuan Lu 的新作

# 11/13
## attention
- **[]** Attention Is All You Need
- **[]** An Empirical Study of Spatial Attention Mechanisms in Deep Networks

### `non-local network` `SE-Net`
- **[NLN]** Non-local Neural Networks
- **[GCNet]** GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond  √
	- 针对`nln`的问题（实验观察nln的缺陷）做出了改进，提供了一个统一的框架，并发现`SENet`是其中一个特例；模块在参数计算方面做了些探讨，使其成为一个轻量级的模块。

# 11/15
## GAN 
### `Adversarial`
- **[VITAL]** VITAL: VIsual Tracking via Adversarial Learning  √
	- CVPR2018 `Spotlight`
	- 在本文中，我们将对抗性学习融入到跟踪-检测框架中，以减少单帧图像的过拟合。 在单帧图像中自适应滤除分类特征，提取分类器信息。 它使分类器能够集中于时间上的鲁棒特征，而这些特征在训练过程中本来就被消除了。 该算法通过对抗性学习实现自适应丢失，根据不同的输入信息预测区分特征。 丰富了特征空间的目标外观，增加了阳性样本。 同时，利用成本敏感性损失，减小了易负样本的影响。
	- 效果还行，就是速度太慢了 1.5fps（模型有更新的原因？）；其实他的两部分GAN/CSL在原基础上提升不大（figure 4），重在创新
	- 文中还分析了tracking的两种：一阶段和两阶段。本文是两阶段—先候选框、再二分类。
- **[SINT++]** SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation
	- 基于SINT，用GAN生成正样本，解决正负样本不平衡的问题
- **[]** Hallucinated Adversarial Learning for Robust Visual Tracking
	- libo李博
- **[]** Siamese adversarial network for object tracking
	- SCI_4

- **[]** Localization-Aware Meta Tracker Guided With Adversarial Features
- 
## pruning
- **[]** Channel pruning for visual tracking
	- ECCV2018

## other
- **[]** Visual tracking based on semantic and similarity learning
	- SCI_4

# 11/16
## detection
### 
- **[]** Relation Networks for Object Detection
	- CVPR2018

- **[]** Momentum Contrast for Unsupervised Visual Representation Learning
	- Kaiming He

# 11/17
## AAAI 2020
- **[SiamFC++]** SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines  √
	- AAAI 2020
	- 充分分析了以前算法的不足（特别是SiamRPN系列），并提出了一套`指南`；针对性的做了改进，精心设计的目标状态估计准则（借鉴了检测里的两三个算法），多个数据集上都是stoa；速度还很快（90fps）
	- backbone不光是AlexNet还有GoogLeNet，这个前面没人尝试过；

- **[DROL]** Discriminative and Robust Online Learning for Siamese Visual Tracking  √
	- AAAI 2020
	- 在Siamese框架下并行的加了一个轻量级的网络来做分类（文中试验了siamfc，siamrpn++，siammask），主要学习背景信息，来区分前景和背景（这也就是Siamese系列没有的，只学习目标信息）；并且还有一个更新策略；效果非常好,`屠榜`，速度也还行>30FPS

# 11/19
## Topologies→Network
- **[]** EDEN: Evolutionary Deep Networks for Efficient Machine Learning
- **[]** Evolving Neural Networks through Augmenting Topologies
- **[]** Neural Network Topologies for Sparse Training
- **[]** Towards a topological-geometrical theory of group equivariant non-expansive operators for data analysis and machine learning
	- Nature子刊
- **[]** Topological change disturbs object continuity in attentive tracking

## 
- **[]** Unsupervised Learning of Visual Representations using Videos
	- ICCV2015  Xiaolong Wang
	- 视频来训练，学习目标帧于帧之间的关系（没看的）
- **[]** Dual Deep Network for Visual Tracking

## Context-aware
- **[CAT]** Learning Cascaded Context-aware Framework for Robust Visual Tracking  √
	- ICCV2019 `Cascaded`  `Context-aware`
	- 先上下文来获取粗略的目标与背景的分类信息、定位；再来细致的物体内部信息来精确定位；这也就是两个网络级联的（先粗再细），文中的image-based context-aware和patch-based context-aware
	- 非Siamese框架
	- 运用了LSTM来获取历史帧的信息，还有RNN，感觉很复杂（不太懂）；速度没也说，估计不会太快；对于Context `我们发现，这样的跟踪器很少考虑连续帧的整个场景的综合判别信息`；

## GCN
- **[GCT]** Graph Convolutional Tracking  √
	- CVPR2019 oral
	- 首次用图卷积做跟踪，其实是在Siamese的框架下嵌入两个图卷积模块，并能端到端的训练、推理；速度还阔以 50FPS；
	- 两个GCN模块，一个时空(spatial-temporal)、一个上下文(context)。用GCN很好的表示了这两个特征、并做和融合（其实先前也有这两个方面的工作，只是没有用GCN，也没有他分析得那么好）；对于GCN不是很了解（对于里面的节点、边的表示），如何与CNN相结合是一个实现上的的难点（还没开源）；


# 11/20
## ICCV 2019
#### tracking
##### SOT
- **[GradNet]** GradNet: Gradient-Guided Network for Visual Object Tracking
	- `oral`
- **[DiMP]** Learning Discriminative Model Prediction for Tracking
	- `oral`
- **[MLT]** Deep Meta Learning for Real-Time Target-Aware Visual Tracking
	- `meta`
- **[SPLT]** 'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking
	- `long-term`
- **[]** Bridging the Gap Between Detection and Tracking: A Unified Approach
	- `Detection and Tracking`
- **[UpdateNet]** Learning the Model Update for Siamese Trackers
	- `update`
- **[GFS-DCF]** Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking

##### MOT
- **[]** FAMNet: Joint Learning of Feature, Affinity and Multi-Dimensional Assignment for Online Multiple Object Tracking
- **[]** Spatial-Temporal Relation Networks for Multi-Object Tracking
- **[]** Robust Multi-Modality Multi-Object Tracking
- **[]** Tracking Without Bells and Whistles

##### Other
- **[]** Joint Monocular 3D Vehicle Detection and Tracking
- **[DeSurT]** Deformable Surface Tracking by Graph Matching
	- 
- **[]** Self-Supervised Moving Vehicle Tracking With Stereo Sound
- **[ARCF]** Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking
	- `UAV`
- **[PAT]** Physical Adversarial Textures That Fool Visual Object Tracking

##### data
- **[CDTB]** CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark



# 11/22
## Topological
- **[]** Deep Learning with Topological Signatures 
	- 没懂！
	- 结论：据我们所知，我们在案例持久性图中提供了学习拓扑特征的任务最优稳定表示的第一种方法。 我们对这一想法的特殊实现，即作为深度神经网络的输入层，不仅使我们能够学习拓扑签名，而且还可以将它们用作现有深度架构的附加（并且可能是互补的）输入。 从理论上讲，我们指出，只要满足引理1的条件，提出的结构元素就不限于指数函数。 然而，提出的方法的一个缺点是通过对数变换对余辉轴（参见图1）进行人工弯曲。 实际上，其他策略可能是可行的，并且更适合某些情况。 有关此问题的详细调查留给以后的工作。 从实践的角度来看，还值得指出的是，原则上，建议的层可用于处理以（Rn）的多集形式出现的任何类型的输入，而以前的工作仅允许处理固定集。 大小（请参见第1节）。 总而言之，我们认为我们的实验显示出有力的证据，表明数据的拓扑特征在许多学习任务中可能是有益的，不一定取代现有的输入，而是作为歧视性信息的补充来源。
	- **[]** A Topology Layer for Machine Learning
		- 没懂!
		- 其中的参考文献有几篇可以看看
		- 结论：我们提出了一个可微的机器学习拓扑层以及三个新的应用。我们在欧几里德数据、图像和机器学习模型的权值中实施拓扑结构。我们构造了一个可微的拓扑损失，使我们能够改进深生成模型。最后，我们比较了在具有拓扑特征的deep模型上基于梯度的对抗攻击和在CNNs和MLPs上的相同攻击。
我们的工作只触及了利用持久性的可微特性的可能方向的表面。毫无疑问，这些工作将解决我们在这里提出的问题以外的问题。这些工作可以包括在深部神经网络的中间激活中鼓励拓扑结构，或者在可能更有用的地方使用深部神经网络中间的层来提取持久性特征。然而，我们在这里介绍的许多应用程序也值得进一步关注。例如，拓扑正则化，包括我们提出的惩罚，可能有有趣的理论性质，或封闭形式的解决方案。据我们所知，这是统计模型中基于持久性的权重正则化的首次演示。此外，使用诸如持久性特征之间的瓶颈或Wasserstein距离之类的距离训练自动编码器可能产生比这里所考虑的函数更强的结果。最后，使用拓扑特性训练更能抵抗对抗性攻击的深层网络可能会证明是有用的，然而，正如我们所展示的，这将需要额外的工作。与局部几何相比，拓扑在机器学习中通常没有得到充分的利用，但改变这种情况可能有利于这门学科。
	- **[]** PI-Net: A Deep Learning Approach to Extract Topological Persistence Images  `☆`
		- 首个提出用数据来学习拓扑特征（持久图persistence images(PIs)），并且端到端的，融合与深度学习（卷积），还加快了计算速度（相比传统的提取PIs特征方法）
		- 思路是把PIs融合到常规的卷积特征中，起到一个特征增强的效果（分类实验（一维时序信号、二维图像）结果只涨了半个点、一个点），还做了抗干扰实验（也只是半个点到一个点的提升）
		- 还有些别的工作，也是把PIs融合到机器学习、神经网络里（紫色标注部分）

	- **[]** A Topological Loss Function for Deep-Learning based Image Segmentation using Persistent Homology
	- **[]** Explicit topological priors for deep-learning based image segmentation using persistent homology
		- James R. Clough 上两篇同一作者
	- **[]** Topology-Preserving Deep Image Segmentation


​	
- **[]** Towards a topological-geometrical theory of group equivariant non-expansive operators for data analysis and machine learning
- **[]** Topological change disturbs object continuity in attentive tracking
- **[]** 



# 11/27
## SiamFC 被引，关于题目有Siamese的论文
- **[]** Siamese Networks: The Tale of Two Manifolds
	- ICCV2019 
- **[]** Hierarchical spatial-aware Siamese network for thermal infrared object tracking
	- SCI_2
- **[]** Masked and dynamic Siamese network for robust visual tracking
	- SCI_1
- **[]** Hyper-feature based tracking with the fully-convolutional Siamese network
	- 垃圾会议；和上一篇同作者，国防科大
	- **[]** Hyper-Siamese network for robust visual tracking
		- SCI_4 和上篇一样的，投完会议又投期刊？
- **[]** Robust real-time visual object tracking via multi-scale fully convolutional Siamese networks
	- SCI_4
	- 分块？
- **[]** An In-Depth Analysis of Visual Tracking with Siamese Neural Networks
	- ☆
- **[]** Long-term object tracking based on siamese network
	- CCF_C
- **[]** Fully Convolutional Siamese Fusion Networks for Object Tracking
	- CCF_C
- **[]** Siamese Networks with Discriminant Correlation Filters and Channel Attention
	- CCF_D
- **[]** Region-based fully convolutional siamese networks for robust real-time visual tracking
	- CCF_D
- **[]** Target-Specific Siamese Attention Network for Real-time Object Tracking
	- SCI_2
- **[]** Describe and Attend to Track: Learning Natural Language guided Structural
Representation and Visual Attention for Object Tracking
	- arxiv
- **[]** Fully Conventional Anchor-Free Siamese Networks for Object Tracking
	- SCI_2
- **[]** Siamese recurrent architecture for visual tracking
	- CCF_D
- **[]** Flow Guided Siamese Network for Visual Tracking
	- CCF_C
- **[]** Siamese Tracking from Single Point Initialization
	- SCI_3
- **[]** Siamese adversarial network for object tracking
	- SCI_4
- **[]** Siamese Feature Pyramid Network for Visual Tracking
	- CCF_D
- **[]** Adaptive Hierarchical Siamese Network for Object Tracking
	- CCF_D
- **[]** Deep Siamese Networks toward Robust Visual Tracking
	- 综述，没下到
- **[]** Visual Tracking Via Siamese Network With Global Similarity
	- CCF_C
- **[]** Siamese Network Using Adaptive Background Superposition Initialization for Real-Time Object Tracking
	- SCI_2
- **[]** DomainSiam: Domain-Aware Siamese Network for Visual Object Tracking
	- CCF_D
- **[]** Cross-Layer Convolutional Siamese Network for Visual Tracking
	- CCF_C
- **[]** Learning to Match Using Siamese Network for Object Tracking
	- CCF_D
- **[]** Dice Loss in Siamese Network for Visual Object Tracking
	- CCF_D
- **[]** Distractor-Aware Visual Tracking by Online Siamese Network
	- SCI_2 ,没下到


# 11/28
## attention
- **[]** Multi attention module for visual tracking
	- SCI_2、卢老师
## Review
- **[]** Deep visual tracking: Review and experimental comparison  ☆
	- SCI_2 、卢老师、2017年
	- 从是三个方面分析了tracking在DL的发展：网络结构、网络功能、训练方式。（详细见图二）