# 11/2



# 11/5
## `Martin Danelljan`
- **[DiMP]** Learning Discriminative Model Prediction for Tracking
	- `discriminative learning`
	- 分析了Siamese learning framework 的[缺陷](https://blog.csdn.net/sinat_31184961/article/details/89512108)：
		- Siamese的网络框架一般都只是把模板割出来，忽略了背景信息的利用，而背景的信息对目标的检测定位也是至关重要的；
		- 因为跟踪一般都是很多没有见过的类，通过offline学习的相似性度量可能不是很适用；
		- 没有一个合适的模型更新方式。
	- 针对性的提出两个[创新点](https://gkwang.net/dimp/)：
		- 首先，作者使用了模型预测网络，并且通过具有判别能力Loss进行优化；
		- 还设计了快速迭代方法进行优化。
			- 在每次梯度下降时，朝向梯度最陡的地方，以计算得到的最优步长进行下降；
			- 设计一个权重预测模块，为模型提供较好的初始化。
	- 还有很多值得学习的地方，比如训练的时候采用的一系列图片，不是以往的单张图片；公式推导，数学很强，很多不是太懂！

- **[ATOM]** ATOM: Accurate tracking by overlap maximization


# 11/11
## `SE-Net`
- **[SE-Net]** 
- **[CMPE-SE]** Competitive Inner-Imaging Squeeze and Excitation for Residual Network

## `Cbam`
- **[Cbam]** 
- **[GENet]** Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
- **[BAM]** BAM: Bottleneck Attention Module
- **[GCNet]** GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond
	- ICCV 2019 `Best Paper Award`
	- 感觉有戏，可以试试（上面三个没有track的paper）
	- `non-local network`

## `dense` 同一作者Gao Huang
- **[DenesNet]** 
- **[CondenseNet]** CondenseNet: An Efficient DenseNet using Learned Group Convolutions
- **[MSDNet]** Multi-Scale Dense Networks for Resource Effciient Imagine Classification

## `Motion Guided Attention`
- **[]** Motion Guided Attention for Video Salient Object Detection
	- ICCV2019
	- 运动引导，这点看看，没准可以用上

## `pruning`
- **[]** Rethinking the Value of Network Rruning

## `tracking` 
### `attention`
- **[RMA-Siam]** Relation-aware Multiple Attention Siamese Networks for Robust Visual Tracking  √
	- bmvc2019(CCF_C)
	- 利用`多个注意`图发现最显著的目标部分，并采用正交正则化方法`保证局部`模式的多样性。然后应用`关系感知语义补偿`来获取零件特征之间的依赖关系。
	- 在基准SiamRPN上做的改进，主要针对`遮挡`问题，效果很不错，速度也很快（180+fps）
	- 感觉多个小创新组合在一起，效果也不错，就是才是一个C类会议。
	- **[]** A2-Nets: Double Attention Networks
	- **[StructSiam]** Structured Siamese Network for Real-Time Visual Tracking
		- `RMA-Siam`和他很像，但有所改进，都是`部分、结构`上做创新
		- 也是卢老师的 ECCV2018

	- **[]** RePr: Improved Training of Convolutional Filters
	- 
### `detection`
- **[]** Bridging the Gap Between Detection and Tracking: A Unified Approach  √
	- ICCV2019
	- 从检测的角度来说思考的track，提供了一个框架，一个新思路，`我们认为跟踪是一个一次目标检测和少次实例分类的联合任务`，还有`meta learning`
	- 就是效果相比而言没有啥提升或是持平，速度上更是只有几帧（有更新策略），相比Siamese差得远（速度提升下一个创新点？！！）

### `Knowledge Distillation`
- **[]** Teacher-Students Knowledge Distillation for Siamese Trackers  √
	- Jianbing Shen 北京理工大学，同工作 SiamFC-tri (ECCV2018)、HASiam (SCI_1)，
	- 第一个对跟踪问题采用知识蒸馏来压缩模型的，压缩的效果确实很好（13x—18x），性能没啥影响甚至还有所提升，速度提升了两三倍

### `Gradient-Guided`
- **[GradNet]** GradNet: Gradient-Guided Network for Visual Object Tracking
	- ICCV2019 `oral` ，Huchuan Lu 的新作

# 11/13
## attention
- **[]** Attention Is All You Need
- **[]** An Empirical Study of Spatial Attention Mechanisms in Deep Networks

### `non-local network` `SE-Net`
- **[NLN]** Non-local Neural Networks
- **[GCNet]** GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond  √
	- 针对`nln`的问题（实验观察nln的缺陷）做出了改进，提供了一个统一的框架，并发现`SENet`是其中一个特例；模块在参数计算方面做了些探讨，使其成为一个轻量级的模块。

# 11/15
## GAN 
### `Adversarial`
- **[VITAL]** VITAL: VIsual Tracking via Adversarial Learning  √
	- CVPR2018 `Spotlight`
	- 在本文中，我们将对抗性学习融入到跟踪-检测框架中，以减少单帧图像的过拟合。 在单帧图像中自适应滤除分类特征，提取分类器信息。 它使分类器能够集中于时间上的鲁棒特征，而这些特征在训练过程中本来就被消除了。 该算法通过对抗性学习实现自适应丢失，根据不同的输入信息预测区分特征。 丰富了特征空间的目标外观，增加了阳性样本。 同时，利用成本敏感性损失，减小了易负样本的影响。
	- 效果还行，就是速度太慢了 1.5fps（模型有更新的原因？）；其实他的两部分GAN/CSL在原基础上提升不大（figure 4），重在创新
	- 文中还分析了tracking的两种：一阶段和两阶段。本文是两阶段—先候选框、再二分类。
- **[SINT++]** SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation
	- 基于SINT，用GAN生成正样本，解决正负样本不平衡的问题
- **[]** Hallucinated Adversarial Learning for Robust Visual Tracking
	- libo李博
- **[]** Siamese adversarial network for object tracking
	- SCI_4

- **[]** Localization-Aware Meta Tracker Guided With Adversarial Features
- 
## pruning
- **[]** Channel pruning for visual tracking
	- ECCV2018

## other
- **[]** Visual tracking based on semantic and similarity learning
	- SCI_4

# 11/16
## detection
### 
- **[]** Relation Networks for Object Detection
	- CVPR2018

- **[]** Momentum Contrast for Unsupervised Visual Representation Learning
	- Kaiming He

# 11/17
## AAAI 2020
- **[SiamFC++]** SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines  √
	- AAAI 2020
	- 充分分析了以前算法的不足（特别是SiamRPN系列），并提出了一套`指南`；针对性的做了改进，精心设计的目标状态估计准则（借鉴了检测里的两三个算法），多个数据集上都是stoa；速度还很快（90fps）
	- backbone不光是AlexNet还有GoogLeNet，这个前面没人尝试过；

- **[DROL]** Discriminative and Robust Online Learning for Siamese Visual Tracking  √
	- AAAI 2020
	- 在Siamese框架下并行的加了一个轻量级的网络来做分类（文中试验了siamfc，siamrpn++，siammask），主要学习背景信息，来区分前景和背景（这也就是Siamese系列没有的，只学习目标信息）；并且还有一个更新策略；效果非常好,`屠榜`，速度也还行>30FPS

# 11/19
## Topologies→Network
- **[]** EDEN: Evolutionary Deep Networks for Efficient Machine Learning
- **[]** Evolving Neural Networks through Augmenting Topologies
- **[]** Neural Network Topologies for Sparse Training
- **[]** Towards a topological-geometrical theory of group equivariant non-expansive operators for data analysis and machine learning
	- Nature子刊
- **[]** Topological change disturbs object continuity in attentive tracking

## 
- **[]** Unsupervised Learning of Visual Representations using Videos
	- ICCV2015  Xiaolong Wang
	- 视频来训练，学习目标帧于帧之间的关系（没看的）
- **[]** Dual Deep Network for Visual Tracking

## Context-aware
- **[CAT]** Learning Cascaded Context-aware Framework for Robust Visual Tracking  √
	- ICCV2019 `Cascaded`  `Context-aware`
	- 先上下文来获取粗略的目标与背景的分类信息、定位；再来细致的物体内部信息来精确定位；这也就是两个网络级联的（先粗再细），文中的image-based context-aware和patch-based context-aware
	- 非Siamese框架
	- 运用了LSTM来获取历史帧的信息，还有RNN，感觉很复杂（不太懂）；速度没也说，估计不会太快；对于Context `我们发现，这样的跟踪器很少考虑连续帧的整个场景的综合判别信息`；

## GCN
- **[GCT]** Graph Convolutional Tracking  √
	- CVPR2019 oral
	- 首次用图卷积做跟踪，其实是在Siamese的框架下嵌入两个图卷积模块，并能端到端的训练、推理；速度还阔以 50FPS；
	- 两个GCN模块，一个时空(spatial-temporal)、一个上下文(context)。用GCN很好的表示了这两个特征、并做和融合（其实先前也有这两个方面的工作，只是没有用GCN，也没有他分析得那么好）；对于GCN不是很了解（对于里面的节点、边的表示），如何与CNN相结合是一个实现上的的难点（还没开源）；


# 11/20
## ICCV 2019
#### tracking
##### SOT
- **[GradNet]** GradNet: Gradient-Guided Network for Visual Object Tracking
	- `oral`
- **[DiMP]** Learning Discriminative Model Prediction for Tracking
	- `oral`
- **[MLT]** Deep Meta Learning for Real-Time Target-Aware Visual Tracking
	- `meta`
- **[SPLT]** 'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking
	- `long-term`
- **[]** Bridging the Gap Between Detection and Tracking: A Unified Approach
	- `Detection and Tracking`
- **[UpdateNet]** Learning the Model Update for Siamese Trackers  √ :sunny:
	- `update`
- **[GFS-DCF]** Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking

##### MOT
- **[]** FAMNet: Joint Learning of Feature, Affinity and Multi-Dimensional Assignment for Online Multiple Object Tracking
- **[]** Spatial-Temporal Relation Networks for Multi-Object Tracking
- **[]** Robust Multi-Modality Multi-Object Tracking
- **[]** Tracking Without Bells and Whistles

##### Other
- **[]** Joint Monocular 3D Vehicle Detection and Tracking
- **[DeSurT]** Deformable Surface Tracking by Graph Matching
	- 
- **[]** Self-Supervised Moving Vehicle Tracking With Stereo Sound
- **[ARCF]** Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking
	- `UAV`
- **[PAT]** Physical Adversarial Textures That Fool Visual Object Tracking

##### data
- **[CDTB]** CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark



# 11/22
## Topological
- **[]** Deep Learning with Topological Signatures 
	- 没懂！
	- 结论：据我们所知，我们在案例持久性图中提供了学习拓扑特征的任务最优稳定表示的第一种方法。 我们对这一想法的特殊实现，即作为深度神经网络的输入层，不仅使我们能够学习拓扑签名，而且还可以将它们用作现有深度架构的附加（并且可能是互补的）输入。 从理论上讲，我们指出，只要满足引理1的条件，提出的结构元素就不限于指数函数。 然而，提出的方法的一个缺点是通过对数变换对余辉轴（参见图1）进行人工弯曲。 实际上，其他策略可能是可行的，并且更适合某些情况。 有关此问题的详细调查留给以后的工作。 从实践的角度来看，还值得指出的是，原则上，建议的层可用于处理以（Rn）的多集形式出现的任何类型的输入，而以前的工作仅允许处理固定集。 大小（请参见第1节）。 总而言之，我们认为我们的实验显示出有力的证据，表明数据的拓扑特征在许多学习任务中可能是有益的，不一定取代现有的输入，而是作为歧视性信息的补充来源。
	- **[]** A Topology Layer for Machine Learning
		- 没懂!
		- 其中的参考文献有几篇可以看看
		- 结论：我们提出了一个可微的机器学习拓扑层以及三个新的应用。我们在欧几里德数据、图像和机器学习模型的权值中实施拓扑结构。我们构造了一个可微的拓扑损失，使我们能够改进深生成模型。最后，我们比较了在具有拓扑特征的deep模型上基于梯度的对抗攻击和在CNNs和MLPs上的相同攻击。
我们的工作只触及了利用持久性的可微特性的可能方向的表面。毫无疑问，这些工作将解决我们在这里提出的问题以外的问题。这些工作可以包括在深部神经网络的中间激活中鼓励拓扑结构，或者在可能更有用的地方使用深部神经网络中间的层来提取持久性特征。然而，我们在这里介绍的许多应用程序也值得进一步关注。例如，拓扑正则化，包括我们提出的惩罚，可能有有趣的理论性质，或封闭形式的解决方案。据我们所知，这是统计模型中基于持久性的权重正则化的首次演示。此外，使用诸如持久性特征之间的瓶颈或Wasserstein距离之类的距离训练自动编码器可能产生比这里所考虑的函数更强的结果。最后，使用拓扑特性训练更能抵抗对抗性攻击的深层网络可能会证明是有用的，然而，正如我们所展示的，这将需要额外的工作。与局部几何相比，拓扑在机器学习中通常没有得到充分的利用，但改变这种情况可能有利于这门学科。
	- **[]** PI-Net: A Deep Learning Approach to Extract Topological Persistence Images  `☆`
		- 首个提出用数据来学习拓扑特征（持久图persistence images(PIs)），并且端到端的，融合与深度学习（卷积），还加快了计算速度（相比传统的提取PIs特征方法）
		- 思路是把PIs融合到常规的卷积特征中，起到一个特征增强的效果（分类实验（一维时序信号、二维图像）结果只涨了半个点、一个点），还做了抗干扰实验（也只是半个点到一个点的提升）
		- 还有些别的工作，也是把PIs融合到机器学习、神经网络里（紫色标注部分）

	- **[]** A Topological Loss Function for Deep-Learning based Image Segmentation using Persistent Homology
	- **[]** Explicit topological priors for deep-learning based image segmentation using persistent homology
		- James R. Clough 上两篇同一作者
	- **[]** Topology-Preserving Deep Image Segmentation


​	
- **[]** Towards a topological-geometrical theory of group equivariant non-expansive operators for data analysis and machine learning
- **[]** Topological change disturbs object continuity in attentive tracking
- **[]** 



# 11/27
## SiamFC 被引，关于题目有Siamese关键词的论文
- **[]** Siamese Networks: The Tale of Two Manifolds
	
	- ICCV2019 
	
- **[]** Hierarchical spatial-aware Siamese network for thermal infrared object tracking
	- Knowledge-Based Systems journal、SCI_1、
	- thermal infrared 热红外跟踪
- [x]  **[SiamAtt]** Target-Specific Siamese Attention Network for Real-time Object Tracking
	
	- IEEE Transactions on Information Forensics and Security、SCI_1
	- *深度相似性跟踪器能够以高于实时的速度进行跟踪。 但是，由于它们避免了有价值的在线提示，因此其准确性大大低于基于深度分类的跟踪器。 为了提供特定于目标的信息以进行实时对象跟踪，我们提出了一种新颖的暹罗注意网络。 **不同类型的注意力机制**用于捕获目标信息的不同上下文，然后将学习到的知识用于在相似性跟踪的不同表示级别提供目标提示。 另外，采用在线学习机制来利用可用的特定于目标的数据。* 
	- 在`SiamFC`基础上集成了**`残差注意力`和`通道注意力`**，并充分分析了这两种注意力带来的好处，还选择了在线微调`通道注意力`（计算开销小）（这里的更新机制没看太明白），消融实验做的很充分；
	- 值得注意的是`训练方式`，**多次分开训练**，避免注意力模块和backbone一起训练带来性能损失；
	
- **[]** Masked and dynamic Siamese network for robust visual tracking
	
	- Information Sciences、SCI_1
	- *由于语义背景和目标模板的简单建模策略导致的分心问题往往会导致性能下降。在本研究中，我们在现有暹罗网路追踪器的基础上，提出两个模组，即目标对象模型和目标模板模型来解决这些问题。目标对象模型根据前景和背景区域的颜色分布，计算搜索区域中与被跟踪目标相关的每个像素的可能性。计算出的目标似然图在先前的响应图上被屏蔽，然后调整最终的响应图以聚焦于目标。这种方法扩大了被跟踪目标与周围背景的区分，从而缓解了干扰问题。目标模板模型采用高斯混合模型对目标外观变化进行编码，模型中的每个分量代表目标的不同方面，并学习和动态更新分量权重。提出的高斯模型在增强分集的同时减少了目标样本之间的冗余度。*
	
- **[]** Hyper-feature based tracking with the fully-convolutional Siamese network
	- 垃圾会议；和上一篇同作者，国防科大
	- **[]** Hyper-Siamese network for robust visual tracking
		- SCI_4 和上篇一样的，投完会议又投期刊？ 
	
- [x] **[FCAF]** Fully Conventional Anchor-Free Siamese Networks for Object Tracking
  
  - IEEE Access、SCI_2
  - 1、整体结构类似`C-RPN`（没引），包括融合模块；2、backbone换成ResNet50（略有改动），这是借鉴`SiamRPN++`，并且为了解决padding的影响，训练方式也是采用的`空间感知采样策略`；3、头部结构在分类，回归分支上新增一个中心`Center-ness`，这也直接借鉴的`FCOS`（没引）。
- 结果只在OTB2015和VOT2016上测试了，结果还行；说能实时，但没说具体多少帧！
  
- [x] **[Siam+LWN+CA+ABSI]** Siamese Network Using Adaptive Background Superposition Initialization for Real-Time Object Tracking ::sunny: ::star2:  
  
  - IEEE Access、SCI_2
  
  - *由于Siamese跟踪器只能通过离线训练来学习相似性度量模型，因此样本分支没有足够的判别信息来适应目标在后续帧中不断变化的外观。我们提出了一种基于暹罗网络的跟踪器，可以提高跟踪性能如下。首先，提出了一种**自适应的背景叠加初始化**方法，并将其应用于示例分支中，以充分利用第一帧中有限的先验信息。其次，提出了一种**轻量级卷积神经网络**作为跟踪器的骨干，它对特征的维数进行压缩以保证速度和精度。第三，将**信道注意模块**引入到跟踪器中，并结合自适应背景叠加初始化。利用通道注意模型调整原始样本图像及其背景变化图像的特征映射，并进行融合，增强样本图像的表现力。**GOT-10k数据集用于训练我们的跟踪器**。*
  
  - 实验做的很充分，测试了OTB、VOT2018；文章书写的很全面，`实验细节`、`参数选择`都有说明（这里多看下）；速度50fps；
  
  - 对于文章的三个创新点，提点还是`网络的设计`上作用更大；
  
  - 但是`自适应背景初始化`是一个很不错的创新点！
  
    > 本文只对第一帧模板进行了背景变化，是否可以对后续帧也采用类似的处理？？
    > 背景自适应，或是说`背景抑制凸显目标`，让目标的特征更强，减少背景干扰（检测有[两篇]()）
    >
    > > Accelerating Object Detection by Erasing Background Activations
    > >
    > > Selective Convolutional Network: An Efficient Object Detector with Ignoring Background
  
  - 训练的数据集只用了`GOT-10k`，并且还与用VID数据集做了对比，GOT-10k更好一些，但是居然没有把GOT-10k的测试结果贴出来（可能结果不太好吧，不好对比）；
  
- **[]** Distractor-Aware Visual Tracking by Online Siamese Network  ::sunny:
  
  - IEEE Access、SCI_2 
  - *大多数基于暹罗网络的跟踪器的想法是离线培训和在线跟踪。 实际上，在线跟踪是根据深度特征进行的，这些深度特征是从经过离线数据训练的预定义网络中提取的。 但是，这些特征是相似对象的一般表示，因此，它们的区分能力不足以从背景中识别当前的跟踪目标，尤其是干扰因素。 为了解决此问题，我们建议**在线更新由暹罗网络提取的功能**。 这些功能可以实时跟踪目标变化。 特别是，我们从离线训练的浅层卷积层中提取出共同特征，然后将它们用作深层卷积层的输入，以在线学习当前目标的特殊特征。 此外，提出了一种集成更新策略来加速网络融合。 增强学习特征从背景和干扰因素中识别当前目标的辨别能力是有益的。*
  
- **[]** Siamese Tracking from Single Point Initialization
  
  - Sensors、SCI_2
  
- **[]** Robust real-time visual object tracking via multi-scale fully convolutional Siamese networks
	- SCI_4
	- 分块？
	
- **[]** Siamese adversarial network for object tracking

  - ELECTRONICS LETTERS、SCI_4
  - 短文

- **[]** Long-term object tracking based on siamese network
	
	- ICIP 2017、CCF_C
	- *在本文中，我们提出了基于暹罗网络的长期跟踪器。 我们解决了长期跟踪的问题，目标对象由于严重变形，遮挡，突然运动和视线不佳而出现明显的外观变化。 为了解决这些问题，我们建议采用**多模板融合**跟踪方案。 此外，提出了基于光流的补丁模板更新方案，以提高整体跟踪性能。*
	- 文章很短，内容感觉不咋地
	
- **[]** Fully Convolutional Siamese Fusion Networks for Object Tracking
	- ICIP 2018、CCF_C
	- *我们采用卷积层的融合策略进行对象跟踪，以基于卷积神经网络实现良好的特征表示。 具体来说，我们基于归一化互相关（NCC）融合了VGGNet的三个卷积层。 首先，我们使用VGGNet的**三个卷积层作为融合**的基础，并基于卷积内核减小卷积层的大小。 然后，我们将卷积层的大小调整为与用于层融合的反卷积层的大小相同。 接下来，我们将基于NCC的三层融合在目标区域和搜索区域之间，并生成响应图。*
	- 实验对比做的不咋地
	
- **[]** Flow Guided Siamese Network for Visual Tracking

  - ICIP 2018、CCF_C
  - *在本文中，我们尝试从两个方面解决这个问题。 首先，我们使用光流来利用帧间信息，当我们获得最后一帧的位置时，我们可以**通过计算光流并在其周围生成样本来预测当前帧的大概位置**。 其次，我们使用跟踪的补丁作为参考来更好地识别目标。 我们设计了一个暹罗网络，该网络以由示例和样本组成的图像对作为输入，还通过添加先验概率来修改目标函数。*

- **[]** Visual Tracking Via Siamese Network With Global Similarity

  - ICIP 2019、CCF_C
  - *基于暹罗网络的跟踪器通过利用成对丢失或三重丢失来训练其网络，这很容易导致过度拟合。 另外，难以区分训练样本中的一些**硬样本**。 在本文中，我们提出了一种新颖的**全局相似度损失**来训练网络。 具体来说，我们利用两个高斯分布来模拟和优化训练集中正样本和负样本的分布，并对硬样本添加约束。*

- **[]** Cross-Layer Convolutional Siamese Network for Visual Tracking

  - ICONIP 2018、CCF_C
  - *目前大多数基于暹罗网络的跟踪器并没有充分挖掘不同层次的语义特征。为此，我们提出了一种跨层卷积暹罗网络跟踪器（Siam-CC），试图从两个方面探索**不同层次的语义特征**。首先，我们结合浅层到深层的跨层卷积响应图来捕捉各种语义感知特征，同时强制Siam-CC只关注最感兴趣的位置，因为更多的语义信息能够减少背景的负面影响。其次，为了进一步提高对响应的识别能力，在传统的物流损失的基础上，增加了一个**自适应的对比损失**，在一定程度上有助于过滤掉一些噪声响应。*

- **[]** Siamese Networks with Discriminant Correlation Filters and Channel Attention
	
	- CCF_D
	
- **[]** Region-based fully convolutional siamese networks for robust real-time visual tracking
	
	- CCF_D
	
- **[]** Siamese recurrent architecture for visual tracking
	
	- CCF_D
	
- **[]** Siamese Feature Pyramid Network for Visual Tracking
	
	- CCF_D
	
- **[]** Adaptive Hierarchical Siamese Network for Object Tracking
	
	- CCF_D
	
- **[]** DomainSiam: Domain-Aware Siamese Network for Visual Object Tracking
	
	- CCF_D
	
- **[]** Learning to Match Using Siamese Network for Object Tracking
	
	- CCF_D
	
- **[]** Dice Loss in Siamese Network for Visual Object Tracking
	
	- CCF_D
	
- **[]** Deep Siamese Networks toward Robust Visual Tracking
	
	- 综述，没下到
- **[]** An In-Depth Analysis of Visual Tracking with Siamese Neural Networks
	
	- arxiv、
	- *这项调查对九种流行追踪器的学习和推理能力进行了深入分析。 它既不是要研究整个文献，也不是为了审查提出用于视觉跟踪的各种神经网络。 相反，我们专注于暹罗神经网络，这是研究跟踪挑战性问题的有希望的起点。 这些网络有效地集成了特征学习和时间匹配功能，并且迄今已显示出最先进的性能。 特别强调了暹罗网络的分支机构，连接这些分支机构的层，培训的特定方面以及将这些网络嵌入到跟踪器中。 将现有论文的定量结果与以下结论进行了比较：现有评估方法显示出结果的可重复性和可比性问题。 本文提出了一种新颖的类似Lisp的形式主义，以更好地比较跟踪器。 假设跟踪器具有一定的功能设计和功能分解。 本文试图通过基于机器学习理论的问题表述以及将跟踪器解释为决策函数，为跟踪器设计奠定基础。 这项工作以有希望的研究结束，并提出了未来的工作建议。*
	
- **[]** Describe and Attend to Track: Learning Natural Language guided Structural Representation and Visual Attention for Object Tracking
	
	  - arxiv
	- 引入NLP
	
	
	

# 11/28
## attention
- **[]** Multi attention module for visual tracking
	- SCI_2、卢老师
## Review
- **[]** Deep visual tracking: Review and experimental comparison  ☆
	- SCI_2 、卢老师、2017年
	- 从是三个方面分析了tracking在DL的发展：网络结构、网络功能、训练方式。（详细见图二）