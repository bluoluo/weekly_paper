# 10/28
## `motion` `rotation`
- **[DSR]** Rotation Adaptive Visual Object Tracking with Motion Consistency √
	- 2018 IEEE Winter Conference on Applications of Computer Vision
	- 主要分析了以往的siamfc、cfnet等方法对于下帧目标定位的`平滑性`，并加以改进从`角度`、`距离`上分析，实验结果也表明确实有点效果；还对scale一致性上进行了分析；最后就Rotation Invariance旋转不变性进行了和siamfc、cfnet结合，这一点的思路很合`SiamBM`类似
- **[]** Motion Correlation Discovery for Visual Tracking
	- IEEE SIGNAL PROCESSING LETTERS (3)
- **[]** Learning Motion-Aware Policies for Robust Visual Tracking 
	- 2019 IEEE International Conference on Multimedia and Expo (ICME) (b)
## `add`
- **[]** Deformable Surface Tracking by Graph Matching
	- `ICCV2019`
- **[]** Learning to Track Any Object
	- arXiv:1910.11844
- **[SiamOS]** One-Shot Scale and Angle Estimation for Fast Visual Object Tracking
	- IEEE Access(2)
	- Inspired by `Siam-BM`
	- 出发点是，考虑到SiamBM计算量大，速度偏慢，在此基础上改进：# siam-os不必每帧执行5次基于dcnn的特征提取，只需计算xk（α，0）的深度卷积特征一次，并通过裁剪、调整大小和旋转fk（α，0）生成5个特征映射，这使得siam os在推断步骤中比siam bm更快、更高效。#
	- 但是相应的在特征的学习、表达上就会稍弱点(作者自己也有说)，特别是在gpu上的实验结果，本文也就强在速度上，以及在cpu上的实验结果

# 10/26
## `motion`
- **[AMNet]** Model-free Tracking with Deep Appearance and Motion Features Integration √
	- 太复杂了，分两个分支——特征信息和运动信息；没看完！
	- ANet，类似Siamese Net，特征提取、匹配；但是采用的很多‘秀’操作，为了高分辨率定位、保持空间结构；
	- MNet，没细看，更是复杂，文中说`帧差法`来获取运动信息；并且还说了，帧差法是比较容易计算的，相比光流。
- **[DMSRDCF]** Deep Motion Features for Visual Tracking √
	- `Martin Danelljan` 马丁大神 ICPR2016(best paper)
	- 手动设计+深度特征+深度运动信息：在前一作SRDCF基础上改进；vgg16；深度运动信息用的optical flow
	- **[]** Deep motion and appearance cues for visual tracking Martin 同一篇，增加了一些分析



# 10/25
## `Optical Flow` 
- **[FlowTrack]**  End-to-end Flow Correlation Tracking with Spatial-temporal Attention 
	- CVPR2018，SenseTime
	- **[FlowNet V1/2]** 
	- **[DOT]** Real-Time Object Tracking with Motion Information  √
		- 在siamfc的基础上增加了一个MotionNet（就是下面论文）分支——用于获取相邻两帧之间的运动信息；对比 *FlowTrack* 和 *SINT++* 只是胜在速度上，那就可以说——是下面这个`快速光流操作`起作用了？
		- 还有点是设计了一个很好的注意力融合机制，可以借鉴！
		- **[MotionNet]** Hidden Two-Stream Convolutional Networks for Action Recognition
			- ACCV2018(C类会议)
			- 快速光流操作

	- **[FPSiam]** Accurate Positioning Siamese Network for Real-Time Object Tracking  √
		- IEEE Access(SCI_2)
		- 很不错的一篇文章（想法和我很相似），用光流信息引导下帧的搜索区域，（感觉还可在深入研究）；光流运动信息使用的FlowNet2，感觉这里很耗时，文中为了加速还多次进行下采样，速度40~50帧；
		- backbone是改进的AlexNet，densely链接五层卷积，还在第五层通道数上做了小改动，以及多层之间的融合策略可以学习；
		- 还有说道cosine windows的影响，在搜索区域，特别是对快速移动的目标，但是说的不清楚；~~还有个知识点ROI pooling操作，没懂~~，就是R-CNN检测中的操作——为了使提议框输出大小一致，还加速了训练等；文中还有几处不是很理解的地方。
	- **[]** Multi-Cue Cascades for Robust Visual Tracking
		- IEEE Access 
- **[SINT++]** SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation
	- CVPR2018
- **[GradNet]** GradNet: Gradient-Guided Network for Visual Object Tracking
	- 卢湖川课题组


## `loss`
- **[SiamFC-tri]** Triplet Loss in Siamese Network for Object Tracking
	- ECCV2018
- **[]** Robust Visual Tracking with Channel Attention and Focal Loss
	- Neurocomputing(SCI_2)


## `Fusion`


# 10/23
## `self-attention`
- **[]** An Empirical Study of Spatial Attention Mechanisms in Deep Networks
	- 总结、比较了attention的几种形式；知乎[`立夏之光`](https://www.zhihu.com/question/319776669/answer/825799683) 的回答
	
- `on-local` attention
## `high-resolition representation`

- **[HRNet]** High-Resolution √
	- 高分辨表示，对于目标特征的表示、定位更好；
	- 网络创新之处在于`维护了高分辨率表示`，而不是以往的`先降再升`的策略；
	- 该backbone用在了很多领域都用不错的效果。

- **[]** Region-based High-resolution Siamese Network for Robust Visual Tracking √
	- 把HRNet的高表征用在了Siamese的backbone部分；
	- 伪Siamese结构——backbone之后模板、搜索分支采用了不同的操作，其中就用到了下面这篇论文的思想——`分块`

- **[]** Robust occlusion-aware part-based visual tracking with object scale adaptation
	- sci_2 (Pattern Recognition)

# 10/12
## `Cropping-Inside Residual (CIR)`
- **[siamDW]** Deeper and Wider Siamese Networks for Real-Time Visual Tracking √
	- CVPR2019oral
	- CIR



# 10/9
## `deep` `width` `cardinality` `scale`
- **[ResNeXt]** Aggregated residual transforma- tions for deep neural networks
	- `cardinality`

- **[DPN]** Dual Path Networks
	- ResNet + DenseNet
- **[Res2Net]** Res2Net: A New Multi-scale Backbone Architecture √
	- `scale`
	- 南开，程明明
	- 

# 9/23
## `trcking` `attention`
- **[HASiam]** Visual Object Tracking by Hierarchical Attention Siamese Network
	- 'IEEE TRANSACTIONS ON CYBERNETICS' `SCI_1`
	
	- 创新点：1）Key Part Searching ，在标注框内在选择更具有代表性的关键部分，搜多方式—`mask覆盖`（反向思考），后面更新也 用关键部分来更新；2）注意力机制`A-Net`，就是把关键部分和第一帧的模板做相关赋予不同的权值；3）特征融合方面，在每层的pooling后都进行融合，Adaptive Fusion Weights也采用了`APCE`，

- **[Siam-BM]** Towards a Better Match in Siamese Network Based Visual Object Tracker
	- `ECCV2018`
	- 在SA-Siam的基础上改进，主要针对是目标物体的旋转变化，还有在目标物体的长宽比尺寸上做了尺度变化
- **[YCNN]** Once for All: a Two-flow Convolutional Neural Network for Visual Tracking
	- `SCI_2`
	- 很早的一篇了，挂在arXiv上面都是1604了，比siamFC都早；网络结构中很像Siamese 但又不是，没细看

# 15 August 2019

## Keypoint tracking

### SATIN 
Siamese Attentional Keypoint Network for High Performance Visual Tracking | [[`pdf`]](https://arxiv.org/abs/1904.10128) ✓


- **[Hourglass]** Stacked Hourglass Networks for Human Pose Estimation | [`[pdf]`](http://arxiv.org/abs/1603.06937) ✓
	- **[MSPN]** Rethinking on Multi-Stage Networks for Human Pose Estimation | [`[pdf]`](https://arxiv.org/abs/1901.00148) 
	- **[ArtTrack]** ArtTrack: Articulated Multi-person Tracking in the Wild Eldar | [`[pdf]`](http://arxiv.org/abs/1612.01465v3)
	- 
- **[CBAM]** CBAM: Convolutional Block Attention Module | [`[pdf]`](http://arxiv.org/abs/1807.06521) 
	- **[SENet]** Squeeze-and-Excitation Networks |[`[pdf]`](http://arxiv.org/abs/1709.01507)
	- 
- **[CornerNet]** CornerNet: Detecting Objects as Paired Keypoints | [`[pdf]`](https://doi.org/10.1007/s11263-019-01204-1)
	- **[CenterNet]** CenterNet: Keypoint Triplets for Object Detection | [`[pdf]`](http://arxiv.org/abs/1904.08189)
	- **[CenterNet']** Objects as Points | [`[pdf]`](http://arxiv.org/abs/1904.07850)
	- 

### LightTrack
LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking |  [`[pdf]`](https://arxiv.org/abs/1905.02822)

### 

## Survey 
- Video Object Segmentation and Tracking: A Survey | [`[pdf]`](http://arxiv.org/abs/1904.09172)
- Object Detection and Tracking : A Survey | [`[pdf]`](http://ieeexplore.ieee.org/document/7546127/)
- Deep Learning in Video Multi-Object Tracking: A Survey | [`[pdf]`](http://arxiv.org/abs/1907.12740)

# 5 September 2019

## attention 



- **[RASNet]** Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking
	- RASNet中注意模型的骨干是一个沙漏状卷积神经网络（cnn）模型[37]，
- **[SATN]** Siamese Attentional Keypoint Network for High Performance Visual Tracking
	- 
- **[MHA-Siam]** Multi-granularity Hierarchical Attention Siamese Network for Visual Tracking
	
	- IJCNN (C级会议)
- **[SA-Siam]** A Twofold Siamese Network for Real-Time Object Tracking
	- 两个孪生网络，语义特征、外观细节  异构，并不是以前那种简单直接的多层融合，两个相互独立分开训练
- **[FICFNet]** End-to-End Feature Integration for Correlation Filter Tracking With Channel Attention
	- IEEE SIGNAL PROCESSING LETTERS 3区期刊
	- 在CFNet基础上设计了一个'Feature Integration'模块，然后运用end-to-end的训练思想，还有就是添加了通道注意力SENet；主干网络还是 AlexNet，也就简单/普通的融合conv2和conv5；
- **[TASNet]** Template Attentional Siamese Network for Object Tracking
	- 垃圾会议？还有一个中文期刊“结合注意力与特征融合的目标跟踪”内容一样的
	
- **[SiamVGG]** SiamVGG: Visual Tracking using Deeper Siamese Networks
	- 骨干网络换成VGG16。对于是否能换成跟深得网络简要的探讨，padding的影响；训练的方法和用了更大的数据集。
	
- **[SiamPF]** A Strong Feature Representation for Siamese Network Tracker 
	- SA-Siam 和 SiamVGG 的结合体，应该说更像前者，改动之处使用了VGG16更深的网络；还有一点是 改进 APCE→APCEP 。
	
	- 还说在VGG上面不适合用 通道注意力 模块？？半信半疑
	
- **[DensSiam]** DensSiam: End-to-End Densely-Siamese Network with Self-Attention Model for Object Tracking
	- 主干网络换成DenseNet，但是居然没有引用，[不懂?]；自注意力机制 ‘Self-Attention’ 这里讲的没太懂；还一直在强调 ’Non-local features‘ 提高网络泛化性！？，归功于Densely network 和Self-Attention？
- **[RAR]** Learning Reinforced Attentional Representation for End-to-End Visual Tracking
	- 增强注意力。帧间注意力+帧内注意力：帧间运用了LSTM这种机制，将跟踪问题表述为顺序推理任务；帧内又有通道和空间注意力（SENet/CBAM）。
	- 整体而言还是CNN提取特征（’注意力‘增强特征效果），在运用DCF来进行判断,跟踪；骨干网络是Resnet50（略微改动），并分析了vgg和其他部分的效果（详细在消融实验部分）。整体而言还是比较复杂的，特别是在LSTM+那几个注意力模块。

- **[ ]** Learning Cascaded Siamese Networks for High Performance Visual Tracking
	- SiamFC + MDNet：两个方法结合(网络级联)，先相似性匹配，再从匹配中得分较高的部分缩放剪切(DSST)出一些候选区域，进而进行分类；针对其方法还提出了一种更新机制。
	- 方法思路很清晰、简单——结合两个解决同一问题的不同方法！可能创新点不是太好，但是思想很巧妙。

- **[HASiam]** Hierarchical attentive Siamese network for real-time visual tracking
	- 通道/空间+非局部 注意力('spatial and channel-wise attentions'  'non-local attention module')，通道/空间注意力还分别放在网络的低中高层，进而融合更多层特征；‘非局部’ 有一点不是太明白？
	- 主干网络还是Alexnet + VGG 两个分支，并没有用两个一样的、更深的VGG，分析还是因为padding的原因。
	- 最后，作者也说网络对于更深的，或是更轻量级的网络试试。
- **[MFFSiam]** Deeper Siamese network with multi-level feature fusion for real-time visual tracking
	- 和上一篇是同一作者(南京信息工程大学)；
	- ”ELECTRONICS LETTERS“ 只是个SCI4区！就论文所呈现的结果来看，不止一个4区啊？！可能创新点不够？
	- 骨干网络用的AlexNet，在后面几层的特征汇聚模块(feature agglomeration module)有所创新——上下两个分支采用了不一样的特征提取/融合策略（generalised non-local attention (GNLA) module and a inception-like module）；虽然都是前人的东西，但是结合后效果还是挺好的。
	- 注意：剪切（crop-operation [11]），消除padding影响操作

- **[NL]** Non-local Neural Networks
	- 从感受野的方面入手，非局部/全局？（没看完）

- **[]** Attention Is All You Need
	- （没看的）
- **[RACT]** Residual Attention Convolutional Network for Online Visual Tracking
	- 把 “Residual Attention” 残差注意力运用到跟踪上，是基于DCF的（这篇没细看完）

- **[IMG-Siam]** Initial Matting-Guided Visual Tracking With Siamese Network
	- 在初始帧的模板中加入了分割策略(initial matting)，增强了初始帧模板的质量。
	- 主干网络还是AlexNet，也添加了通道注意力。


## backbone network

- **[Attention-92]** Residual Attention Network for Image Classificatio
	- 设计了一种残差结构的注意力模块(基于ResNet)，模块可以嵌入到其他网络中。

- **[SKNet]** Selective Kernel Networks
	- "SENet" 的衍生，多了个选择性——对于不同的 感受野可以动态调节。
