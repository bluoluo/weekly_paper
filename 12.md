# 补
## 
- **[SPSTracker]** SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking
	- AAAI 2020、
	- `ATOM`上改进的

- **[Siam R-CNN]** Siam R-CNN: Visual Tracking by Re-Detection

- **[DomainSiam]** DomainSiam: Domain-Aware Siamese Network for Visual Object Tracking
	- 和`DenseSiam`一个作者
## anchor-free
- **[SiamCAR]** SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking  √ ☆
	- arXiv
	- 1、把跟踪问题还是看成分类与回归问题，但是更加极致——逐像素的，这也是在`FCOS`的启发下——既无建议框也无锚（`both proposal and anchor free`），并且分类回归的基础上增加了`center-ness`分支；2、匹配的响应图这里只有一个，不像其他的RPN方法分开的，即在一个响应图后在分别做分类和回归，这里的响应图和SiamRPN++一样采用的是深度互相关操作（`Depth-wise Cross Correlation`），得到的响应图就不是单独的一层，通道数这里保持一致256；
	- 这篇叙述的比较详细在细节上；实验结果也很棒，在GOT-10k、LaSOT、UAV123上表现的很强；测试了OTB50，没测OTB100？也没有测试VOT；速度不错50+fps。


- **[FCAF]** Fully Conventional Anchor-Free Siamese Networks for Object Tracking  √
	- IEEEE Access
	- 1、整体结构类似`C-RPN`（没引），包括融合模块；2、backbone换成ResNet50（略有改动），这是借鉴`SiamRPN++`，并且为了解决padding的影响，训练方式也是采用的`空间感知采样策略`；3、头部结构在分类，回归分支上新增一个中心`Center-ness`，这也直接借鉴的`FCOS`（没引）。
	- 结果只在OTB2015和VOT2016上测试了，结果还行；说能实时，但没说具体多少帧！

## 
- **[SiamMan]** SiamMan: Siamese Motion-aware Network for Visual Tracking
	- AAAI 2020
	- 有部分启发于`GCNet`
	- 1、是基于`anchor`的分类、回归，再加一个定位分支（Localization branch）用于粗定位（受`CenterNet`启发）；2、在定位分支里还运用了`GCNet`来捕获远程相关性，使其对`大位移`具有更强的鲁棒性；3、三个分支都使用了`多尺度注意力模块`来进行特征融合增强；
	- 实验结果很不错，速度也挺快的45fps。

## detection
- **[FCOS]** FCOS: Fully Convolutional One-Stage Object Detection
	- ICCV 2019

- **[]** Acquisition of localization confidence for accurate object detection



# 20/12
## `long-term`
- **[GlobalTrack]** GlobalTrack: A Simple and Strong Baseline for Long-term Tracking  √
	- AAAI 2020
	- Bridging the Gap Between Detection and Tracking: A Unified Approach ，同一作者，这一篇也是检测做跟踪，本篇做的更加极致
	- 把跟踪问题看成一个`纯粹的全局实例搜索`（‘a pure global instance search’）；受`两阶段`（`Faster-RCNN`）检测的启发——两阶段的跟踪：QG-RPN + QG-RCNN；
	- 针对跟踪问题而设计的`询问引到Query-guided`策略和`交叉询问损失Cross-query Loss`；这里实现细节带看代码细品！！
	- 其实也就是以前对检测和跟踪不太理解的地方，核心思想：`单个类别的、特定的目标检测`。具体实现上做得更加简单有效，效果很好，特别是在长期跟踪中的目标消失在出现的情况，就是速度`太慢`（几帧），没办法，全局搜索计算量很大。
	- 还有一点很值得`注意`：没有累计误差。‘其核心思想是消除局部性假设，使跟踪器能够在任意位置和尺度上搜索目标，从而避免跟踪过程中的累积误差’。因为每一帧都是全局搜索，没有受到前面跟踪的影响（？）；也没有对其目标的位子、尺度、大小等信息进行假设限制。

# 24/12
## tracking
### stork
- **[]** Dynamical Hyperparameter Optimization via Deep Reinforcement Learning in Tracking
	- TPAMI、Jianbing Shen（北理）
- **[]** Selective Spatial Regularization by Reinforcement Learned Decision Making for Object Tracking
	- TIP

# 29/12
## tracking
### stork
- **[MDSLT]** Visual Object Tracking via Multi-Stream Deep Similarity Learning Networks
	- TIP

### [IEEE search](https://ieeexplore.ieee.org/search/advanced)（OT、VT、Siam、19）
- **[DP-Siam]** DP-Siam: Dynamic Policy Siamese Network for Robust Object Tracking
	- TIP、
	- DensSiam、DomainSiam同一作者
- **[FlowSiam]** Weighted Optical Flow Prediction and Attention Model for Object Tracking
	- IEEE Access
	- `flow` + `attention`
- **[]** Efficient Convolution Neural Networks for Object Tracking Using Separable Convolution and Filter Pruning
	- IEEE Access
	- 对 SiamFC 加速：可分离卷积+滤波剪枝。

